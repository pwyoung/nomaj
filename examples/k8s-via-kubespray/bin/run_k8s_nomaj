#!/bin/bash

# PURPOSE
# - Ensure the VMs are up, by re-running only the Vagrant step
#     nomaj -m vagrant
# - Create an SSH tunnel to the K8S "control-plane" node
#     ssh -f -N -L $host_port:localhost:$container_port $SSH_ALIAS
# - Create a Kube config file
#     ~/.kube/config.local
# - Test
#     KUBECONFIG=$HOME/.kube/config.local kubectl get all
#
# Requirements
# - Do NOT bind port 6443 on this host
#     since it will be used by the nginx-proxy
#     when this node joins the cluster
# - The nomaj repo is installed in ~/git/nomaj
#     cd ~/git/nomaj/examples/k8s-via-kubespray && make
# - "nomaj" is found in $PATH
#     e.g. ~/.bash_profile has
#     PATH=$PATH:~/git/nomaj
# - The nomaj job was run already
#     That job has added SSH alias "k-1" to ~/.ssh/config
#     The following works: "ssh k-1 hostname"
#     cd ~/git/nomaj/examples/k8s-via-kubespray && make

set -e

# SSH to this host (to get kubeconfig and for SSH tunnel to K8S API)
SSH_ALIAS="k-1"
container_port="6443"
# Moved this since nginx-proxy tries to bind to 6443
host_port="6444"


# Start the VMs comprising the K8S cluster.
# This assumes that the VMs were created and configured with K8S.
start_vms() {

    D=~/git/nomaj/examples/k8s-via-kubespray/build/vagrant
    if [ -e $D ]; then
        cd $D
        N=$(vagrant status | grep 'libvirt' | grep 'running' | wc -l)
        echo "Found $N nodes running"
        if [ $N -ge 5 ]; then
            echo "Not running vagrant again"
            sleep 0.5
            return
        fi
    fi

    cd ~/git/nomaj/examples/k8s-via-kubespray
    if nomaj -m vagrant; then
        echo "Started VMs"
    else
        echo "Failed to start VMs"
        echo "Maybe you need to create the cluster with:"
        echo "  cd ~/git/nomaj/examples/k8s-via-kubespray && make"
        exit 1
    fi

    vagrant global-status
}


# This makes an SSH-tunnel network connection
connect_to_k8s_via_tunnel() {
    echo "This works but is deprecated"
    exit 1

    # Make a tunnel from the host to the Master
    # node (VM) in the nomaj K8S cluster
    if ! ps eax | grep -v grep | grep "ssh -f -N -L $host_port:localhost:$container_port $SSH_ALIAS" | awk '{print $1}'; then
        echo "Start SSH tunnel"
        ssh -f -N -L $host_port:localhost:$container_port $SSH_ALIAS
    else
        echo "SSH Tunnel already exists"
    fi

    # Create a KUBE config file that works with the tunnel
    mkdir -p ~/.kube
    F1=~/.kube/config.local.temp
    ssh $SSH_ALIAS "sudo su - -c 'cat /root/.kube/config' 2>/dev/null" > $F1
    # Do not bind to 6443 on this host since it will also be a worker node
    # which runs nginx-proxy on 6443
    F2=~/.kube/config.local
    cat $F1 | perl -pe "s/6443/$host_port/g" > $F2
    chmod 700 $F2
}

# This makes a direct network connection
connect_to_k8s_directly() {
    # Create a KUBE config file that specifies the accessible control node
    mkdir -p ~/.kube
    F1=~/.kube/config.local.temp
    ssh $SSH_ALIAS "sudo su - -c 'cat /root/.kube/config' 2>/dev/null" > $F1

    # Get the IP of "k-1".
    # "k-1" is added to /etc/hosts by Kubespray, but don't assume that ran yet
    D=~/git/nomaj/examples/k8s-via-kubespray/build/vagrant
    IP=$(cd $D && vagrant ssh k-1 -c 'ip a s' | grep eth0 | grep inet | awk '{print $2}' | cut -d '/' -f 1)

    # Replace the connection IP with the known host name "k-1"
    F2=~/.kube/config.local
    cat $F1 | perl -pe "s/127.0.0.1/$IP/g" > $F2
    chmod 700 $F2
}

connect_to_k8s() {
    #connect_to_k8s_via_tunnel
    connect_to_k8s_directly
}

use_kube_config_local() {
    SEP="--------------------------------------------------------------------------------"
    echo "$SEP"
    echo "KUBECONFIG=$HOME/.kube/config.local kubectl config view"
    echo "$SEP"
    KUBECONFIG=$HOME/.kube/config.local kubectl config view
    echo ""
    echo ""
    echo ""

    echo "$SEP"
    echo "KUBECONFIG=$HOME/.kube/config.local kubectl get all,pv,pvc,secret --all-namespaces"
    echo "$SEP"
    KUBECONFIG=$HOME/.kube/config.local kubectl get all,pv,pvc,secret --all-namespaces

    return 0
}

start_vms
connect_to_k8s
use_kube_config_local
